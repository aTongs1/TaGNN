model TaGNN
dataset XIHU
trainval_ratio 0.8
val_ratio 0.125
num_nodes 39
seq_len 12
horizon 1
input_dim 6
output_dim 5
num_rnn_layers 1
rnn_units 64
loss mask_mae_loss
epochs 2000
batch_size 64
base_lr 0.005
use_curriculum_learning True
knn_k 10
dim_fc 672
train xs.shape, ys.shape torch.Size([4404, 39, 12, 6]) torch.Size([4404, 6])
val xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
test xs.shape, ys.shape torch.Size([1467, 39, 12, 6]) torch.Size([1467, 6])
Epoch [1/2000] (68) train_loss: 16.9000, val_loss: 6.6883, lr: 0.005000, 12.4s 
Epoch [2/2000] (136) train_loss: 6.6136, val_loss: 5.7182, lr: 0.005000, 11.3s 
Epoch [3/2000] (204) train_loss: 11.7473, val_loss: 12.3919, lr: 0.005000, 11.3s 
Epoch [4/2000] (272) train_loss: 14.8631, val_loss: 7.5092, lr: 0.005000, 11.4s 
Epoch [5/2000] (340) train_loss: 13.3498, val_loss: 6.9146, lr: 0.005000, 11.3s 
Epoch [6/2000] (408) train_loss: 11.5232, val_loss: 6.0264, lr: 0.005000, 11.3s 
Epoch [7/2000] (476) train_loss: 11.1592, val_loss: 5.7357, lr: 0.005000, 11.4s 
Epoch [8/2000] (544) train_loss: 10.9884, val_loss: 5.8076, lr: 0.005000, 11.4s 
Epoch [9/2000] (612) train_loss: 10.8111, val_loss: 5.7963, lr: 0.005000, 11.3s 
Epoch [10/2000] (680) train_loss: 10.7748, val_loss: 5.4682, lr: 0.005000, 11.3s 
Epoch [11/2000] (748) train_loss: 10.7000, val_loss: 5.5285, lr: 0.005000, 11.2s 
Epoch [12/2000] (816) train_loss: 10.5533, val_loss: 5.8443, lr: 0.005000, 11.2s 
Epoch [13/2000] (884) train_loss: 10.5633, val_loss: 5.3962, lr: 0.005000, 11.2s 
Epoch [14/2000] (952) train_loss: 10.4310, val_loss: 5.1947, lr: 0.005000, 11.1s 
Epoch [15/2000] (1020) train_loss: 10.3659, val_loss: 5.2450, lr: 0.005000, 11.2s 
Epoch [16/2000] (1088) train_loss: 10.4215, val_loss: 5.4519, lr: 0.005000, 11.2s 
Epoch [17/2000] (1156) train_loss: 10.3402, val_loss: 5.5287, lr: 0.005000, 11.2s 
Epoch [18/2000] (1224) train_loss: 10.1207, val_loss: 5.1959, lr: 0.005000, 11.2s 
Epoch [19/2000] (1292) train_loss: 10.1199, val_loss: 5.2920, lr: 0.005000, 11.1s 
Epoch [20/2000] (1360) train_loss: 10.1033, val_loss: 5.4568, lr: 0.000500, 11.2s 
Epoch [21/2000] (1428) train_loss: 9.8108, val_loss: 5.1028, lr: 0.000500, 11.2s 
Epoch [22/2000] (1496) train_loss: 9.6604, val_loss: 5.0923, lr: 0.000500, 11.2s 
Epoch [23/2000] (1564) train_loss: 9.6108, val_loss: 5.2682, lr: 0.000500, 11.2s 
Epoch [24/2000] (1632) train_loss: 9.6065, val_loss: 5.0692, lr: 0.000500, 11.2s 
Epoch [25/2000] (1700) train_loss: 9.5951, val_loss: 5.0377, lr: 0.000500, 11.2s 
Epoch [26/2000] (1768) train_loss: 9.5762, val_loss: 5.0314, lr: 0.000500, 11.2s 
Epoch [27/2000] (1836) train_loss: 9.5396, val_loss: 5.0557, lr: 0.000500, 11.2s 
Epoch [28/2000] (1904) train_loss: 9.5335, val_loss: 5.0715, lr: 0.000500, 11.1s 
Epoch [29/2000] (1972) train_loss: 9.5124, val_loss: 5.0363, lr: 0.000500, 11.2s 
Epoch [30/2000] (2040) train_loss: 9.4844, val_loss: 4.9916, lr: 0.000050, 11.2s 
Epoch [31/2000] (2108) train_loss: 9.4494, val_loss: 5.0449, lr: 0.000050, 11.2s 
Epoch [32/2000] (2176) train_loss: 9.4386, val_loss: 5.0254, lr: 0.000050, 11.2s 
Epoch [33/2000] (2244) train_loss: 9.4157, val_loss: 4.9867, lr: 0.000050, 11.2s 
Epoch [34/2000] (2312) train_loss: 9.4364, val_loss: 5.0265, lr: 0.000050, 11.2s 
Epoch [35/2000] (2380) train_loss: 9.4185, val_loss: 5.0579, lr: 0.000050, 11.2s 
Epoch [36/2000] (2448) train_loss: 9.4235, val_loss: 5.0183, lr: 0.000050, 11.1s 
Epoch [37/2000] (2516) train_loss: 9.4216, val_loss: 5.0262, lr: 0.000050, 11.2s 
Epoch [38/2000] (2584) train_loss: 9.4193, val_loss: 5.0096, lr: 0.000050, 11.2s 
Epoch [39/2000] (2652) train_loss: 9.4226, val_loss: 5.0324, lr: 0.000050, 11.3s 
Epoch [40/2000] (2720) train_loss: 9.4205, val_loss: 5.0524, lr: 0.000005, 11.1s 
Epoch [41/2000] (2788) train_loss: 9.4136, val_loss: 5.0334, lr: 0.000005, 11.2s 
Epoch [42/2000] (2856) train_loss: 9.3963, val_loss: 5.0230, lr: 0.000005, 11.2s 
Epoch [43/2000] (2924) train_loss: 9.4041, val_loss: 5.0229, lr: 0.000005, 11.3s 
Early stopping at epoch: 42 
===================================Best model performance=================================== 
Horizon 1: loss: 4.7536, mae: 4.7495, mape: 44.4449, rmse: 9.2620, r2: 0.9955 
train xs.shape, ys.shape torch.Size([4404, 39, 12, 6]) torch.Size([4404, 6])
val xs.shape, ys.shape torch.Size([1467, 39, 12, 6]) torch.Size([1467, 6])
test xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
Epoch [1/2000] (68) train_loss: 18.7702, val_loss: 15.8391, lr: 0.005000, 11.5s 
Epoch [2/2000] (136) train_loss: 10.2449, val_loss: 8.2890, lr: 0.005000, 11.3s 
Epoch [3/2000] (204) train_loss: 14.9511, val_loss: 19.0704, lr: 0.005000, 11.2s 
Epoch [4/2000] (272) train_loss: 20.4838, val_loss: 10.5521, lr: 0.005000, 11.2s 
Epoch [5/2000] (340) train_loss: 14.5543, val_loss: 5.6362, lr: 0.005000, 11.2s 
Epoch [6/2000] (408) train_loss: 11.4837, val_loss: 5.5641, lr: 0.005000, 11.3s 
Epoch [7/2000] (476) train_loss: 11.3432, val_loss: 5.7251, lr: 0.005000, 11.4s 
Epoch [8/2000] (544) train_loss: 11.0607, val_loss: 5.6269, lr: 0.005000, 11.3s 
Epoch [9/2000] (612) train_loss: 10.7979, val_loss: 5.2484, lr: 0.005000, 11.3s 
Epoch [10/2000] (680) train_loss: 10.6927, val_loss: 5.6720, lr: 0.005000, 11.2s 
Epoch [11/2000] (748) train_loss: 10.7428, val_loss: 5.1266, lr: 0.005000, 11.3s 
Epoch [12/2000] (816) train_loss: 10.6464, val_loss: 5.6341, lr: 0.005000, 11.2s 
Epoch [13/2000] (884) train_loss: 10.4601, val_loss: 5.1376, lr: 0.005000, 11.3s 
Epoch [14/2000] (952) train_loss: 10.4166, val_loss: 4.9669, lr: 0.005000, 11.2s 
Epoch [15/2000] (1020) train_loss: 10.4485, val_loss: 5.3397, lr: 0.005000, 11.3s 
Epoch [16/2000] (1088) train_loss: 10.3316, val_loss: 5.0364, lr: 0.005000, 11.3s 
Epoch [17/2000] (1156) train_loss: 10.2395, val_loss: 5.0918, lr: 0.005000, 11.3s 
Epoch [18/2000] (1224) train_loss: 10.2599, val_loss: 4.9713, lr: 0.005000, 11.3s 
Epoch [19/2000] (1292) train_loss: 10.1856, val_loss: 4.9222, lr: 0.005000, 11.4s 
Epoch [20/2000] (1360) train_loss: 10.3248, val_loss: 5.2798, lr: 0.000500, 11.5s 
Epoch [21/2000] (1428) train_loss: 9.8691, val_loss: 4.9280, lr: 0.000500, 11.4s 
Epoch [22/2000] (1496) train_loss: 9.7251, val_loss: 4.9209, lr: 0.000500, 11.3s 
Epoch [23/2000] (1564) train_loss: 9.6941, val_loss: 4.7931, lr: 0.000500, 11.4s 
Epoch [24/2000] (1632) train_loss: 9.6320, val_loss: 4.8823, lr: 0.000500, 11.3s 
Epoch [25/2000] (1700) train_loss: 9.6082, val_loss: 4.9388, lr: 0.000500, 11.4s 
Epoch [26/2000] (1768) train_loss: 9.5770, val_loss: 4.9133, lr: 0.000500, 11.6s 
Epoch [27/2000] (1836) train_loss: 9.5546, val_loss: 4.8365, lr: 0.000500, 11.3s 
Epoch [28/2000] (1904) train_loss: 9.5323, val_loss: 4.8876, lr: 0.000500, 11.4s 
Epoch [29/2000] (1972) train_loss: 9.5103, val_loss: 4.8678, lr: 0.000500, 11.3s 
Epoch [30/2000] (2040) train_loss: 9.4782, val_loss: 4.8431, lr: 0.000050, 11.5s 
Epoch [31/2000] (2108) train_loss: 9.4557, val_loss: 4.8609, lr: 0.000050, 11.4s 
Epoch [32/2000] (2176) train_loss: 9.4305, val_loss: 4.9126, lr: 0.000050, 11.3s 
Epoch [33/2000] (2244) train_loss: 9.4327, val_loss: 4.8724, lr: 0.000050, 11.6s 
Early stopping at epoch: 32 
===================================Best model performance=================================== 
Horizon 1: loss: 5.1494, mae: 5.1405, mape: 43.7725, rmse: 10.5296, r2: 0.9940 
train xs.shape, ys.shape torch.Size([4403, 39, 12, 6]) torch.Size([4403, 6])
val xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
test xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
Epoch [1/2000] (68) train_loss: 22.3066, val_loss: 10.0404, lr: 0.005000, 11.0s 
Epoch [2/2000] (136) train_loss: 7.4409, val_loss: 6.0063, lr: 0.005000, 11.1s 
Epoch [3/2000] (204) train_loss: 18.5354, val_loss: 14.0304, lr: 0.005000, 11.0s 
Epoch [4/2000] (272) train_loss: 13.2399, val_loss: 5.8681, lr: 0.005000, 10.9s 
Epoch [5/2000] (340) train_loss: 11.2536, val_loss: 6.1306, lr: 0.005000, 11.1s 
Epoch [6/2000] (408) train_loss: 10.3392, val_loss: 5.7756, lr: 0.005000, 11.2s 
Epoch [7/2000] (476) train_loss: 8.8455, val_loss: 6.3182, lr: 0.005000, 11.1s 
Epoch [8/2000] (544) train_loss: 8.2736, val_loss: 5.4894, lr: 0.005000, 11.2s 
Epoch [9/2000] (612) train_loss: 7.9269, val_loss: 5.4327, lr: 0.005000, 11.1s 
Epoch [10/2000] (680) train_loss: 7.9607, val_loss: 5.5054, lr: 0.005000, 11.1s 
Epoch [11/2000] (748) train_loss: 7.7199, val_loss: 5.3929, lr: 0.005000, 11.2s 
Epoch [12/2000] (816) train_loss: 7.6768, val_loss: 5.5530, lr: 0.005000, 11.2s 
Epoch [13/2000] (884) train_loss: 7.5588, val_loss: 5.3931, lr: 0.005000, 11.2s 
Epoch [14/2000] (952) train_loss: 7.4191, val_loss: 5.5131, lr: 0.005000, 11.2s 
Epoch [15/2000] (1020) train_loss: 7.2671, val_loss: 5.9346, lr: 0.005000, 11.2s 
Epoch [16/2000] (1088) train_loss: 7.1612, val_loss: 5.2938, lr: 0.005000, 11.1s 
Epoch [17/2000] (1156) train_loss: 7.3105, val_loss: 5.9001, lr: 0.005000, 11.2s 
Epoch [18/2000] (1224) train_loss: 7.0656, val_loss: 5.3757, lr: 0.005000, 11.2s 
Epoch [19/2000] (1292) train_loss: 7.1394, val_loss: 5.3053, lr: 0.005000, 11.1s 
Epoch [20/2000] (1360) train_loss: 7.1021, val_loss: 5.2442, lr: 0.000500, 11.1s 
Epoch [21/2000] (1428) train_loss: 6.6377, val_loss: 5.1282, lr: 0.000500, 11.1s 
Epoch [22/2000] (1496) train_loss: 6.5585, val_loss: 5.0930, lr: 0.000500, 11.0s 
Epoch [23/2000] (1564) train_loss: 6.4922, val_loss: 5.0736, lr: 0.000500, 11.0s 
Epoch [24/2000] (1632) train_loss: 6.4704, val_loss: 5.0611, lr: 0.000500, 11.0s 
Epoch [25/2000] (1700) train_loss: 6.4463, val_loss: 5.1882, lr: 0.000500, 11.0s 
Epoch [26/2000] (1768) train_loss: 6.4449, val_loss: 5.1310, lr: 0.000500, 11.1s 
Epoch [27/2000] (1836) train_loss: 6.4158, val_loss: 5.1030, lr: 0.000500, 11.1s 
Epoch [28/2000] (1904) train_loss: 6.3766, val_loss: 5.1571, lr: 0.000500, 11.0s 
Epoch [29/2000] (1972) train_loss: 6.3750, val_loss: 5.0907, lr: 0.000500, 11.2s 
Epoch [30/2000] (2040) train_loss: 6.3722, val_loss: 5.0838, lr: 0.000050, 11.3s 
Epoch [31/2000] (2108) train_loss: 6.3015, val_loss: 5.0776, lr: 0.000050, 11.2s 
Epoch [32/2000] (2176) train_loss: 6.2731, val_loss: 5.0805, lr: 0.000050, 11.2s 
Epoch [33/2000] (2244) train_loss: 6.2867, val_loss: 5.0910, lr: 0.000050, 11.3s 
Epoch [34/2000] (2312) train_loss: 6.2863, val_loss: 5.1066, lr: 0.000050, 11.3s 
Early stopping at epoch: 33 
===================================Best model performance=================================== 
Horizon 1: loss: 4.9100, mae: 4.8915, mape: 43.7081, rmse: 9.6415, r2: 0.9951 
train xs.shape, ys.shape torch.Size([4403, 39, 12, 6]) torch.Size([4403, 6])
val xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
test xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
Epoch [1/2000] (68) train_loss: 19.1979, val_loss: 15.0500, lr: 0.005000, 11.2s 
Epoch [2/2000] (136) train_loss: 10.4043, val_loss: 5.6528, lr: 0.005000, 11.3s 
Epoch [3/2000] (204) train_loss: 6.3553, val_loss: 5.7548, lr: 0.005000, 11.2s 
Epoch [4/2000] (272) train_loss: 6.0620, val_loss: 5.5306, lr: 0.005000, 11.3s 
Epoch [5/2000] (340) train_loss: 6.0400, val_loss: 5.4598, lr: 0.005000, 11.2s 
Epoch [6/2000] (408) train_loss: 5.5716, val_loss: 5.6204, lr: 0.005000, 11.2s 
Epoch [7/2000] (476) train_loss: 5.6548, val_loss: 5.7886, lr: 0.005000, 11.3s 
Epoch [8/2000] (544) train_loss: 5.1284, val_loss: 5.6114, lr: 0.005000, 11.4s 
Epoch [9/2000] (612) train_loss: 5.2509, val_loss: 5.2476, lr: 0.005000, 11.2s 
Epoch [10/2000] (680) train_loss: 5.0331, val_loss: 5.6660, lr: 0.005000, 13.6s 
Epoch [11/2000] (748) train_loss: 5.2598, val_loss: 5.8552, lr: 0.005000, 11.6s 
Epoch [12/2000] (816) train_loss: 4.8214, val_loss: 5.2522, lr: 0.005000, 11.1s 
Epoch [13/2000] (884) train_loss: 4.8419, val_loss: 5.7737, lr: 0.005000, 11.4s 
Epoch [14/2000] (952) train_loss: 4.8897, val_loss: 5.6153, lr: 0.005000, 11.2s 
Epoch [15/2000] (1020) train_loss: 5.1720, val_loss: 5.6873, lr: 0.005000, 11.2s 
Epoch [16/2000] (1088) train_loss: 4.9198, val_loss: 5.3812, lr: 0.005000, 11.2s 
Epoch [17/2000] (1156) train_loss: 5.1235, val_loss: 5.2492, lr: 0.005000, 11.2s 
Epoch [18/2000] (1224) train_loss: 4.5374, val_loss: 5.2424, lr: 0.005000, 11.2s 
Epoch [19/2000] (1292) train_loss: 4.4999, val_loss: 5.2632, lr: 0.005000, 11.2s 
Epoch [20/2000] (1360) train_loss: 4.5093, val_loss: 5.2060, lr: 0.000500, 11.2s 
Epoch [21/2000] (1428) train_loss: 4.1281, val_loss: 5.1026, lr: 0.000500, 11.2s 
Epoch [22/2000] (1496) train_loss: 3.9915, val_loss: 5.0156, lr: 0.000500, 11.1s 
Epoch [23/2000] (1564) train_loss: 3.9370, val_loss: 4.9976, lr: 0.000500, 11.1s 
Epoch [24/2000] (1632) train_loss: 3.8954, val_loss: 5.1399, lr: 0.000500, 11.2s 
Epoch [25/2000] (1700) train_loss: 3.8446, val_loss: 4.9691, lr: 0.000500, 11.2s 
Epoch [26/2000] (1768) train_loss: 3.8519, val_loss: 5.0034, lr: 0.000500, 11.2s 
Epoch [27/2000] (1836) train_loss: 3.8164, val_loss: 4.9687, lr: 0.000500, 11.6s 
Epoch [28/2000] (1904) train_loss: 3.8055, val_loss: 4.9874, lr: 0.000500, 11.2s 
Epoch [29/2000] (1972) train_loss: 3.7844, val_loss: 4.9264, lr: 0.000500, 11.2s 
Epoch [30/2000] (2040) train_loss: 3.7685, val_loss: 4.9456, lr: 0.000050, 11.2s 
Epoch [31/2000] (2108) train_loss: 3.7299, val_loss: 4.9991, lr: 0.000050, 11.2s 
Epoch [32/2000] (2176) train_loss: 3.7138, val_loss: 4.9419, lr: 0.000050, 11.2s 
Epoch [33/2000] (2244) train_loss: 3.7121, val_loss: 4.9477, lr: 0.000050, 11.1s 
Epoch [34/2000] (2312) train_loss: 3.6987, val_loss: 4.9865, lr: 0.000050, 11.6s 
Epoch [35/2000] (2380) train_loss: 3.6971, val_loss: 4.9349, lr: 0.000050, 11.8s 
Epoch [36/2000] (2448) train_loss: 3.6994, val_loss: 4.9377, lr: 0.000050, 11.3s 
Epoch [37/2000] (2516) train_loss: 3.6773, val_loss: 4.9304, lr: 0.000050, 11.3s 
Epoch [38/2000] (2584) train_loss: 3.6720, val_loss: 4.9498, lr: 0.000050, 11.1s 
Epoch [39/2000] (2652) train_loss: 3.6725, val_loss: 4.9290, lr: 0.000050, 11.2s 
Early stopping at epoch: 38 
===================================Best model performance=================================== 
Horizon 1: loss: 4.9319, mae: 4.9312, mape: 48.0607, rmse: 10.8143, r2: 0.9938 
train xs.shape, ys.shape torch.Size([4403, 39, 12, 6]) torch.Size([4403, 6])
val xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
test xs.shape, ys.shape torch.Size([1468, 39, 12, 6]) torch.Size([1468, 6])
Epoch [1/2000] (68) train_loss: 18.9449, val_loss: 16.2519, lr: 0.005000, 11.5s 
Epoch [2/2000] (136) train_loss: 10.3052, val_loss: 6.3628, lr: 0.005000, 11.3s 
Epoch [3/2000] (204) train_loss: 6.2614, val_loss: 5.6365, lr: 0.005000, 11.3s 
Epoch [4/2000] (272) train_loss: 5.7492, val_loss: 8.8438, lr: 0.005000, 11.2s 
Epoch [5/2000] (340) train_loss: 16.6155, val_loss: 16.8222, lr: 0.005000, 11.6s 
Epoch [6/2000] (408) train_loss: 16.9661, val_loss: 8.5719, lr: 0.005000, 12.3s 
Epoch [7/2000] (476) train_loss: 11.8440, val_loss: 6.1501, lr: 0.005000, 11.2s 
Epoch [8/2000] (544) train_loss: 11.1655, val_loss: 5.7937, lr: 0.005000, 11.3s 
Epoch [9/2000] (612) train_loss: 11.0405, val_loss: 5.9946, lr: 0.005000, 11.2s 
Epoch [10/2000] (680) train_loss: 10.9530, val_loss: 5.5226, lr: 0.005000, 11.3s 
Epoch [11/2000] (748) train_loss: 10.8662, val_loss: 5.6500, lr: 0.005000, 11.2s 
Epoch [12/2000] (816) train_loss: 10.8398, val_loss: 5.4101, lr: 0.005000, 11.3s 
Epoch [13/2000] (884) train_loss: 10.7763, val_loss: 5.2788, lr: 0.005000, 11.3s 
Epoch [14/2000] (952) train_loss: 10.7472, val_loss: 5.2984, lr: 0.005000, 11.3s 
Epoch [15/2000] (1020) train_loss: 10.4183, val_loss: 5.4391, lr: 0.005000, 11.2s 
Epoch [16/2000] (1088) train_loss: 10.3376, val_loss: 5.3873, lr: 0.005000, 11.2s 
Epoch [17/2000] (1156) train_loss: 10.1836, val_loss: 5.2147, lr: 0.005000, 11.2s 
Epoch [18/2000] (1224) train_loss: 10.1107, val_loss: 5.2018, lr: 0.005000, 11.9s 
Epoch [19/2000] (1292) train_loss: 10.0427, val_loss: 5.4961, lr: 0.005000, 11.6s 
Epoch [20/2000] (1360) train_loss: 10.2086, val_loss: 5.6489, lr: 0.000500, 11.4s 
Epoch [21/2000] (1428) train_loss: 9.8905, val_loss: 5.0685, lr: 0.000500, 11.5s 
Epoch [22/2000] (1496) train_loss: 9.7061, val_loss: 5.0426, lr: 0.000500, 11.4s 
Epoch [23/2000] (1564) train_loss: 9.6944, val_loss: 5.0740, lr: 0.000500, 11.4s 
Epoch [24/2000] (1632) train_loss: 9.6205, val_loss: 5.0431, lr: 0.000500, 11.3s 
Epoch [25/2000] (1700) train_loss: 9.5764, val_loss: 5.0091, lr: 0.000500, 11.3s 
Epoch [26/2000] (1768) train_loss: 9.5638, val_loss: 4.9980, lr: 0.000500, 11.3s 
Epoch [27/2000] (1836) train_loss: 9.5273, val_loss: 5.0799, lr: 0.000500, 11.2s 
Epoch [28/2000] (1904) train_loss: 9.5320, val_loss: 5.0817, lr: 0.000500, 11.9s 
Epoch [29/2000] (1972) train_loss: 9.5111, val_loss: 5.0342, lr: 0.000500, 11.7s 
Epoch [30/2000] (2040) train_loss: 9.4903, val_loss: 5.0118, lr: 0.000050, 12.9s 
Epoch [31/2000] (2108) train_loss: 9.4540, val_loss: 5.0246, lr: 0.000050, 11.2s 
Epoch [32/2000] (2176) train_loss: 9.4415, val_loss: 4.9948, lr: 0.000050, 11.7s 
Epoch [33/2000] (2244) train_loss: 9.4483, val_loss: 4.9601, lr: 0.000050, 11.4s 
Epoch [34/2000] (2312) train_loss: 9.4287, val_loss: 4.9924, lr: 0.000050, 11.4s 
Epoch [35/2000] (2380) train_loss: 9.4325, val_loss: 5.0131, lr: 0.000050, 12.2s 
Epoch [36/2000] (2448) train_loss: 9.4356, val_loss: 4.9885, lr: 0.000050, 11.4s 
Epoch [37/2000] (2516) train_loss: 9.4265, val_loss: 5.0098, lr: 0.000050, 11.2s 
Epoch [38/2000] (2584) train_loss: 9.4319, val_loss: 4.9814, lr: 0.000050, 11.2s 
Epoch [39/2000] (2652) train_loss: 9.4288, val_loss: 4.9960, lr: 0.000050, 11.3s 
Epoch [40/2000] (2720) train_loss: 9.4123, val_loss: 5.0225, lr: 0.000005, 12.5s 
Epoch [41/2000] (2788) train_loss: 9.4103, val_loss: 4.9696, lr: 0.000005, 11.2s 
Epoch [42/2000] (2856) train_loss: 9.4018, val_loss: 4.9971, lr: 0.000005, 12.2s 
Epoch [43/2000] (2924) train_loss: 9.4171, val_loss: 4.9727, lr: 0.000005, 11.5s 
Early stopping at epoch: 42 
===================================Best model performance=================================== 
Horizon 1: loss: 5.0079, mae: 5.0049, mape: 46.8416, rmse: 10.0301, r2: 0.9946 
OUR training and testing ended Sun Nov 17 03:57:02 2024
